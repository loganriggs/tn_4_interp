{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8546443",
   "metadata": {},
   "source": [
    "# Compression\n",
    "Doing compression with modular addition to see how it affects interaction matrices and computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932ecb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45539072",
   "metadata": {},
   "source": [
    "## Compact experiment: bottleneck sweep for modular addition (P=61)\n",
    "This notebook runs a lean experiment that trains bilinear+projection models for `(a+b) mod 64` across varying hidden/bottleneck dimensions.\n",
    "It records the smallest hidden dimension that achieves perfect generalisation (100% accuracy on the full dataset) and lets you inspect interaction matrices via a slider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db22a60",
   "metadata": {},
   "source": [
    "Inputs $a$ and $b$ are each encoded by encoding an element from $0$ to $P-1$ in a $P$ dimensional one-hot vector. The input $(a,b)$ then is encoded in a $2P$ dimensional vector obtained by concatenating the two embeddings of the input numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# Compact experiment: imports and model definitions\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# Bilinear layer similar to the other notebook (left/right via chunk)\n",
    "class Bilinear(nn.Linear):\n",
    "    def __init__(self, d_in: int, d_out: int, bias=False) -> None:\n",
    "        super().__init__(d_in, 2 * d_out, bias=bias)\n",
    "    def forward(self, x):\n",
    "        left, right = super().forward(x).chunk(2, dim=-1)\n",
    "        return left * right\n",
    "    @property\n",
    "    def w_l(self):\n",
    "        return self.weight.chunk(2, dim=0)[0]\n",
    "    @property\n",
    "    def w_r(self):\n",
    "        return self.weight.chunk(2, dim=0)[1]\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    p: int = 61\n",
    "    d_hidden: int | None = None\n",
    "    bias: bool = False\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.bi_linear = Bilinear(d_in=2*cfg.p, d_out=cfg.d_hidden, bias=cfg.bias)\n",
    "        self.projection = nn.Linear(cfg.d_hidden, cfg.p, bias=cfg.bias)\n",
    "    def forward(self, x):\n",
    "        return self.projection(self.bi_linear(x))\n",
    "    @property\n",
    "    def w_l(self):\n",
    "        return self.bi_linear.w_l\n",
    "    @property\n",
    "    def w_r(self):\n",
    "        return self.bi_linear.w_r\n",
    "    @property\n",
    "    def w_p(self):\n",
    "        return self.projection.weight\n",
    "\n",
    "def init_model(p, d_hidden):\n",
    "    cfg = ModelConfig(p=p, d_hidden=d_hidden, bias=False)\n",
    "    return Model(cfg)\n",
    "\n",
    "# Data generation for modular addition\n",
    "def generate_modular_addition_data(P: int):\n",
    "    a_vals = torch.arange(P).repeat_interleave(P)\n",
    "    b_vals = torch.arange(P).repeat(P)\n",
    "    a_1hot = F.one_hot(a_vals, num_classes=P).float()\n",
    "    b_1hot = F.one_hot(b_vals, num_classes=P).float()\n",
    "    x_1hot = torch.cat((a_1hot, b_1hot), dim=-1)\n",
    "    targets = (a_vals + b_vals) % P\n",
    "    return x_1hot, targets\n",
    "\n",
    "# Create train/validation split (no separate test set)\n",
    "def make_splits(x, y, train_frac=0.8, batch_size=256):\n",
    "    # shuffle\n",
    "    n = x.size(0)\n",
    "    perm = torch.randperm(n)\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    n_train = int(train_frac * n)\n",
    "    x_train = x[:n_train]\n",
    "    y_train = y[:n_train]\n",
    "    x_val = x[n_train:]\n",
    "    y_val = y[n_train:]\n",
    "    train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    val_ds = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, (x_val, y_val)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84b90d",
   "metadata": {},
   "source": [
    "Train with cross-entropy loss, having a Bilinear Layer in a Transformer architecture in mind, where the last predictive step is done via softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7590ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training helper ready\n"
     ]
    }
   ],
   "source": [
    "# Training utilities (lean) - now uses train and validation loaders\n",
    "def train_model(model, train_loader, val_loader, epochs=500, lr=3e-3, weight_decay=1e-4):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    for ep in tqdm(range(epochs), desc='epochs'):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, tb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            tb = tb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, tb)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "        avg_loss = sum(losses)/len(losses) if len(losses)>0 else 0.0\n",
    "        history['train_loss'].append(avg_loss)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for xb, tb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                tb = tb.to(device)\n",
    "                logits = model(xb)\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                correct += (preds == tb).sum().item()\n",
    "                total += tb.numel()\n",
    "            val_acc = correct/total if total>0 else 0.0\n",
    "        history['val_acc'].append(val_acc)\n",
    "        if val_acc == 1.0:\n",
    "            print(f\"Grokking at epoch {ep}.\")\n",
    "            break\n",
    "    return model, history, epochs\n",
    "\n",
    "print('Training helper ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5418d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 12769\n",
      "\n",
      "Training d_hidden=113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<07:44,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<08:14,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:35,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:43,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<08:26,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:09,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:38,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:07,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<07:24,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:41,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:43,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:08,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<08:58,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:11,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/600 [00:01<08:11,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 2.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<06:55,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:20,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:25,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<06:55,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:52,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 4/600 [00:03<08:23,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 4.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 4/600 [00:02<07:15,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 4.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:42,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:20,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:59,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:48,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:51,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<09:39,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 6/600 [00:04<07:21,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 6.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:40,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 4/600 [00:02<07:06,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 4.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:45,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 4/600 [00:02<07:03,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 4.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:10,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 7/600 [00:04<06:39,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 7.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 6/600 [00:03<06:14,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 6.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 4/600 [00:02<07:13,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 4.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<07:39,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 6/600 [00:04<06:38,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 6.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:35,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 3/600 [00:02<08:09,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 3.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   1%|          | 6/600 [00:03<06:34,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 6.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   2%|â–         | 10/600 [00:05<05:22,  1.83it/s]"
     ]
    }
   ],
   "source": [
    "# Run the sweep: P=64, dims 1..64, up to 400 epochs each (stops when first perfect model found)\n",
    "P = 113\n",
    "x, y = generate_modular_addition_data(P)\n",
    "print('Dataset size:', x.size(0))\n",
    "\n",
    "# We'll sweep dims from no-bottleneck (d=P) down to d=1 so the slider can go P->1\n",
    "dims = list(range(P, 0, -1))\n",
    "max_epochs = 600\n",
    "wd = 3e-4\n",
    "lr = 3e-3\n",
    "models_state = {}\n",
    "val_acc = {}\n",
    "# create splits once (same dataset across dims)\n",
    "train_loader, val_loader, test_pair = make_splits(x, y, train_frac=0.75, batch_size=64)\n",
    "x_test, y_test = test_pair\n",
    "generalizes = True\n",
    "for d in dims:\n",
    "    print(f'\\nTraining d_hidden={d}')\n",
    "    m = init_model(P, d)\n",
    "    trained, hist, used_epochs = train_model(m, train_loader, val_loader, epochs=max_epochs, \n",
    "                                             lr=lr, weight_decay=wd)\n",
    "    val_acc[d] = hist['val_acc'][-1] if len(hist['val_acc'])>0 else 0.0\n",
    "    if generalizes and val_acc[d] < 1.0:\n",
    "        print(f\"Model stops fully generalizing at bottleneck dim {d}.\")\n",
    "        print(f\"Validation accuracy: {val_acc[d]:.3f}\")\n",
    "        generalizes = False\n",
    "    elif not generalizes and val_acc[d] == 1.0:\n",
    "        print(f\"Model generalizes again at bottleneck dim {d}.\")\n",
    "        generalizes = True\n",
    "    else:\n",
    "        print(f\"Validation accuracy: {val_acc[d]:.3f}\")\n",
    "    # save state dict on CPU to keep memory reasonable\n",
    "    models_state[d] = {k: v.cpu().clone() for k, v in trained.state_dict().items()}\n",
    "    \n",
    "\n",
    "# Save to disk (also remainder used, e.g. P=64)\n",
    "date = datetime.datetime.now()\n",
    "with open(f'sweep_results_{date.strftime(\"%d%m\")}.pkl', 'wb') as f:\n",
    "    pickle.dump({'P': P, 'val_accs': val_acc, 'models': models_state}, f)\n",
    "print('Saved sweep_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9a2bd",
   "metadata": {},
   "source": [
    "$P=113$ trains orders of magnitude faster than $P=64$ with the chosen hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bffa8e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi_interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
