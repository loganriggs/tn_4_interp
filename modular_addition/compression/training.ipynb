{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8546443",
   "metadata": {},
   "source": [
    "# Compression\n",
    "Doing compression with modular addition to see how it affects interaction matrices and computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932ecb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45539072",
   "metadata": {},
   "source": [
    "## Compact experiment: bottleneck sweep for modular addition (P=64)\n",
    "This notebook runs a lean experiment that trains bilinear+projection models for `(a+b) mod 64` across varying hidden/bottleneck dimensions.\n",
    "It records the smallest hidden dimension that achieves perfect generalisation (100% accuracy on the full dataset) and lets you inspect interaction matrices via a slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd9a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# Compact experiment: imports and model definitions\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from einops import einsum\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# Bilinear layer similar to the other notebook (left/right via chunk)\n",
    "class Bilinear(nn.Linear):\n",
    "    def __init__(self, d_in: int, d_out: int, bias=False) -> None:\n",
    "        super().__init__(d_in, 2 * d_out, bias=bias)\n",
    "    def forward(self, x):\n",
    "        left, right = super().forward(x).chunk(2, dim=-1)\n",
    "        return left * right\n",
    "    @property\n",
    "    def w_l(self):\n",
    "        return self.weight.chunk(2, dim=0)[0]\n",
    "    @property\n",
    "    def w_r(self):\n",
    "        return self.weight.chunk(2, dim=0)[1]\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    p: int = 64\n",
    "    d_hidden: int | None = None\n",
    "    bias: bool = False\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.bi_linear = Bilinear(d_in=2*cfg.p, d_out=cfg.d_hidden, bias=cfg.bias)\n",
    "        self.projection = nn.Linear(cfg.d_hidden, cfg.p, bias=cfg.bias)\n",
    "    def forward(self, x):\n",
    "        return self.projection(self.bi_linear(x))\n",
    "    @property\n",
    "    def w_l(self):\n",
    "        return self.bi_linear.w_l\n",
    "    @property\n",
    "    def w_r(self):\n",
    "        return self.bi_linear.w_r\n",
    "    @property\n",
    "    def w_p(self):\n",
    "        return self.projection.weight\n",
    "\n",
    "def init_model(p, d_hidden):\n",
    "    cfg = ModelConfig(p=p, d_hidden=d_hidden, bias=False)\n",
    "    return Model(cfg)\n",
    "\n",
    "# Data generation for modular addition\n",
    "def generate_modular_addition_data(P: int):\n",
    "    a_vals = torch.arange(P).repeat_interleave(P)\n",
    "    b_vals = torch.arange(P).repeat(P)\n",
    "    a_1hot = F.one_hot(a_vals, num_classes=P).float()\n",
    "    b_1hot = F.one_hot(b_vals, num_classes=P).float()\n",
    "    x_1hot = torch.cat((a_1hot, b_1hot), dim=-1)\n",
    "    targets = (a_vals + b_vals) % P\n",
    "    return x_1hot, targets\n",
    "\n",
    "# Create train/validation split (no separate test set)\n",
    "def make_splits(x, y, train_frac=0.8, batch_size=256):\n",
    "    # shuffle\n",
    "    n = x.size(0)\n",
    "    perm = torch.randperm(n)\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    n_train = int(train_frac * n)\n",
    "    x_train = x[:n_train]\n",
    "    y_train = y[:n_train]\n",
    "    x_val = x[n_train:]\n",
    "    y_val = y[n_train:]\n",
    "    train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    val_ds = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, (x_val, y_val)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84b90d",
   "metadata": {},
   "source": [
    "Train with cross-entropy loss, having a Bilinear Layer in a Transformer architecture in mind, where the last predictive step is done via softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7590ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training helper ready\n"
     ]
    }
   ],
   "source": [
    "# Training utilities (lean) - now uses train and validation loaders\n",
    "def train_model(model, train_loader, val_loader, epochs=500, lr=3e-3, weight_decay=1e-4):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    for ep in tqdm(range(epochs), desc='epochs'):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, tb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            tb = tb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, tb)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "        avg_loss = sum(losses)/len(losses) if len(losses)>0 else 0.0\n",
    "        history['train_loss'].append(avg_loss)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for xb, tb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                tb = tb.to(device)\n",
    "                logits = model(xb)\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                correct += (preds == tb).sum().item()\n",
    "                total += tb.numel()\n",
    "            val_acc = correct/total if total>0 else 0.0\n",
    "        history['val_acc'].append(val_acc)\n",
    "        if val_acc == 1.0:\n",
    "            print(f\"Grokking at epoch {ep}.\")\n",
    "            break\n",
    "    return model, history, epochs\n",
    "\n",
    "print('Training helper ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5418d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4096\n",
      "\n",
      "Training d_hidden=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:13<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 64.\n",
      "Validation accuracy: 0.996\n",
      "\n",
      "Training d_hidden=63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  43%|████▎     | 258/600 [00:32<00:42,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 258.\n",
      "Model generalizes again at bottleneck dim 63.\n",
      "\n",
      "Training d_hidden=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  89%|████████▊ | 532/600 [01:07<00:08,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 532.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  85%|████████▌ | 510/600 [01:07<00:11,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 510.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:20<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 60.\n",
      "Validation accuracy: 0.999\n",
      "\n",
      "Training d_hidden=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  49%|████▊     | 292/600 [00:40<00:42,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 292.\n",
      "Model generalizes again at bottleneck dim 59.\n",
      "\n",
      "Training d_hidden=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:14<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 58.\n",
      "Validation accuracy: 0.996\n",
      "\n",
      "Training d_hidden=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:21<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:17<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.998\n",
      "\n",
      "Training d_hidden=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  33%|███▎      | 199/600 [00:28<00:58,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 199.\n",
      "Model generalizes again at bottleneck dim 55.\n",
      "\n",
      "Training d_hidden=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:26<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 54.\n",
      "Validation accuracy: 0.998\n",
      "\n",
      "Training d_hidden=53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:22<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.993\n",
      "\n",
      "Training d_hidden=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:15<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.993\n",
      "\n",
      "Training d_hidden=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  74%|███████▎  | 441/600 [00:53<00:19,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 441.\n",
      "Model generalizes again at bottleneck dim 51.\n",
      "\n",
      "Training d_hidden=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:13<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 50.\n",
      "Validation accuracy: 0.995\n",
      "\n",
      "Training d_hidden=49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  69%|██████▉   | 413/600 [00:50<00:22,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 413.\n",
      "Model generalizes again at bottleneck dim 49.\n",
      "\n",
      "Training d_hidden=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:13<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 48.\n",
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:14<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.992\n",
      "\n",
      "Training d_hidden=46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:16<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.994\n",
      "\n",
      "Training d_hidden=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  69%|██████▉   | 413/600 [00:50<00:22,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 413.\n",
      "Model generalizes again at bottleneck dim 45.\n",
      "\n",
      "Training d_hidden=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  81%|████████  | 484/600 [00:59<00:14,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 484.\n",
      "Validation accuracy: 1.000\n",
      "\n",
      "Training d_hidden=43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:16<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 43.\n",
      "Validation accuracy: 0.999\n",
      "\n",
      "Training d_hidden=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.991\n",
      "\n",
      "Training d_hidden=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:13<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:14<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.994\n",
      "\n",
      "Training d_hidden=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  78%|███████▊  | 468/600 [01:00<00:16,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grokking at epoch 468.\n",
      "Model generalizes again at bottleneck dim 38.\n",
      "\n",
      "Training d_hidden=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:15<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stops fully generalizing at bottleneck dim 37.\n",
      "Validation accuracy: 0.991\n",
      "\n",
      "Training d_hidden=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.994\n",
      "\n",
      "Training d_hidden=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:16<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.975\n",
      "\n",
      "Training d_hidden=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.998\n",
      "\n",
      "Training d_hidden=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:17<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.991\n",
      "\n",
      "Training d_hidden=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:10<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.993\n",
      "\n",
      "Training d_hidden=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:03<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.993\n",
      "\n",
      "Training d_hidden=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.987\n",
      "\n",
      "Training d_hidden=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:09<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.988\n",
      "\n",
      "Training d_hidden=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.985\n",
      "\n",
      "Training d_hidden=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.997\n",
      "\n",
      "Training d_hidden=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.998\n",
      "\n",
      "Training d_hidden=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.996\n",
      "\n",
      "Training d_hidden=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.961\n",
      "\n",
      "Training d_hidden=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.976\n",
      "\n",
      "Training d_hidden=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.967\n",
      "\n",
      "Training d_hidden=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.987\n",
      "\n",
      "Training d_hidden=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.972\n",
      "\n",
      "Training d_hidden=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.963\n",
      "\n",
      "Training d_hidden=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.934\n",
      "\n",
      "Training d_hidden=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.959\n",
      "\n",
      "Training d_hidden=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.931\n",
      "\n",
      "Training d_hidden=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.967\n",
      "\n",
      "Training d_hidden=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.937\n",
      "\n",
      "Training d_hidden=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:12<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.856\n",
      "\n",
      "Training d_hidden=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:01<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.938\n",
      "\n",
      "Training d_hidden=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:07<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.895\n",
      "\n",
      "Training d_hidden=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.827\n",
      "\n",
      "Training d_hidden=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.769\n",
      "\n",
      "Training d_hidden=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:10<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.873\n",
      "\n",
      "Training d_hidden=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:10<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.419\n",
      "\n",
      "Training d_hidden=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.159\n",
      "\n",
      "Training d_hidden=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 600/600 [01:11<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.026\n",
      "Saved compression_sweep_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Run the sweep: P=64, dims 1..64, up to 400 epochs each (stops when first perfect model found)\n",
    "P = 64\n",
    "x, y = generate_modular_addition_data(P)\n",
    "print('Dataset size:', x.size(0))\n",
    "\n",
    "# We'll sweep dims from no-bottleneck (d=P) down to d=1 so the slider can go P->1\n",
    "dims = list(range(P, 0, -1))\n",
    "max_epochs = 600\n",
    "wd = 3e-4\n",
    "lr = 3e-3\n",
    "models_state = {}\n",
    "int_mats, val_acc = {}, {}\n",
    "remainders = [0, 5, 22, 42, 63]\n",
    "# create splits once (same dataset across dims)\n",
    "train_loader, val_loader, test_pair = make_splits(x, y, train_frac=0.75, batch_size=64)\n",
    "x_test, y_test = test_pair\n",
    "generalizes = True\n",
    "for d in dims:\n",
    "    print(f'\\nTraining d_hidden={d}')\n",
    "    m = init_model(P, d)\n",
    "    trained, hist, used_epochs = train_model(m, train_loader, val_loader, epochs=max_epochs, \n",
    "                                             lr=lr, weight_decay=wd)\n",
    "    val_acc[d] = hist['val_acc'][-1] if len(hist['val_acc'])>0 else 0.0\n",
    "    if generalizes and val_acc[d] < 1.0:\n",
    "        print(f\"Model stops fully generalizing at bottleneck dim {d}.\")\n",
    "        print(f\"Validation accuracy: {val_acc[d]:.3f}\")\n",
    "        generalizes = False\n",
    "    elif not generalizes and val_acc[d] == 1.0:\n",
    "        print(f\"Model generalizes again at bottleneck dim {d}.\")\n",
    "        generalizes = True\n",
    "    else:\n",
    "        print(f\"Validation accuracy: {val_acc[d]:.3f}\")\n",
    "    # save state dict on CPU to keep memory reasonable\n",
    "    models_state[d] = {k: v.cpu().clone() for k, v in trained.state_dict().items()}\n",
    "    # compute interaction matrices for the remainders\n",
    "    mats = []\n",
    "    with torch.no_grad():\n",
    "        for r in remainders:\n",
    "            q = einsum(trained.w_p[r].to('cpu'), trained.w_l.to('cpu'), trained.w_r.to('cpu'), 'hid, hid in1, hid in2 -> in1 in2')\n",
    "            q = 0.5 * (q + q.mT)\n",
    "            mats.append(q)\n",
    "    int_mats[d] = torch.stack(mats, dim=0)\n",
    "\n",
    "# Save to disk\n",
    "date = datetime.datetime.now()\n",
    "with open(f'sweep_results_{date.strptime(\"%d%m\")}.pkl', 'wb') as f:\n",
    "    pickle.dump({'val_accs': val_acc, 'models': models_state, 'int_mats': int_mats, 'remainders': remainders}, f)\n",
    "print('Saved sweep_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9a2bd",
   "metadata": {},
   "source": [
    "Looking at the more compressed values (d=16), one seees that the main circuits is still visible  in the weights, but similar circuits are also visible, albeit at a smaller scale. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi_interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
